{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_colab_to_webpage.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "e1cDMWdOjJ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
      ]
    },
    {
      "metadata": {
        "id": "248xIjNGCRU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configure this notebook to work with your GitHub account by populating these fields."
      ]
    },
    {
      "metadata": {
        "id": "RKrPqZ6Q7CE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten, MaxPool2D, Conv2D, Conv1D, GlobalMaxPooling1D, MaxPooling1D ,Dense, LSTM, RNN, Dropout, GRU, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import tensorflowjs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ft9uEY7UCH46",
        "colab_type": "code",
        "outputId": "dec9270b-f7d8-41f8-a9c5-82801ad0ee93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (0.6.7)\n",
            "Requirement already satisfied: keras==2.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0->tensorflowjs) (40.6.2)\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-preprocessing, keras-applications\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "Successfully installed keras-applications-1.0.4 keras-preprocessing-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jMAqQrbCroQh"
      },
      "cell_type": "markdown",
      "source": [
        "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR11PDl9rnbQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A few snippets from Alice in Wonderland\n",
        "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
        "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
        "\n",
        "# Dracula\n",
        "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
        "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "\n",
        "# Illiad\n",
        "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
        "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EY51wbWkrmx2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = [ex1, ex2, ex3, ex4, ex5, ex6]\n",
        "y_train = [0, 0, 1, 1, 2, 2] # Indicating which book each sentence is from"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oy1Q-25JrlFf"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the documents, create a word index (word -> number)."
      ]
    },
    {
      "metadata": {
        "id": "HOHTxREVQalF",
        "colab_type": "code",
        "outputId": "6ccc1a9d-11a4-4373-ce4a-c69897dfe5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mqyqHuLwWT-Z",
        "colab_type": "code",
        "outputId": "20ce578d-3585-4e26-db72-60e941270cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'was': 2, 'to': 3, 'of': 4, 'at': 5, 'her': 6, 'sister': 7, 'on': 8, 'or': 9, 'had': 10, 'it': 11, 'scepticism': 12, 'as': 13, 'knowledge': 14, 'is': 15, 'alice': 16, 'beginning': 17, 'get': 18, 'very': 19, 'tired': 20, 'sitting': 21, 'by': 22, 'bank': 23, 'once': 24, 'twice': 25, 'she': 26, 'peeped': 27, 'into': 28, 'book': 29, 'reading': 30, 'but': 31, 'no': 32, 'pictures': 33, 'conversations': 34, 'in': 35, 'buda': 36, 'pesth': 37, 'seems': 38, 'a': 39, 'wonderful': 40, 'place': 41, 'left': 42, 'munich': 43, '8': 44, '35': 45, 'p': 46, 'm': 47, '1st': 48, 'may': 49, 'arriving': 50, 'vienna': 51, 'early': 52, 'next': 53, 'morning': 54, 'much': 55, 'result': 56, 'be': 57, 'content': 58, 'with': 59, 'what': 60, 'we': 61, 'present': 62, 'know': 63, 'for': 64, 'most': 65, 'part': 66, 'shut': 67, 'our': 68, 'ears': 69, 'against': 70, 'conviction': 71}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feIAyrrxYFoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how we vectorize a document."
      ]
    },
    {
      "metadata": {
        "id": "Jfi7tJbHTwIc",
        "colab_type": "code",
        "outputId": "9eafeb38-6f7d-4616-b8bd-ed47888f4c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([ex1])\n",
        "print(vectorized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16, 2, 17, 3, 18, 19, 20, 4, 21, 22, 6, 7, 8, 1, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vUfL6MVhYHof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply padding if necessary."
      ]
    },
    {
      "metadata": {
        "id": "rbghRbY5QaMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xwd6ND_UIKk",
        "colab_type": "code",
        "outputId": "d96edf90-28b7-438b-cc95-4bae591f4bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9NUXTTuYLZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
      ]
    },
    {
      "metadata": {
        "id": "UpzusXHhULBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l57eA3ApZGsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a model."
      ]
    },
    {
      "metadata": {
        "id": "oLQeTh3uVqtj",
        "colab_type": "code",
        "outputId": "4de53ddc-700f-4eb5-8955-d8c463513e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 8)             8000      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 483       \n",
            "=================================================================\n",
            "Total params: 8,483\n",
            "Trainable params: 8,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6VOtCRJiYWZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare some training data."
      ]
    },
    {
      "metadata": {
        "id": "-Q8Y1ZuZYYKC",
        "colab_type": "code",
        "outputId": "c3dfd4fe-7a3f-40f7-e2d3-5f694e049402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]\n",
            " [25 26 10 27 28  1 29  6  7  2 30 31 11 10 32 33  9 34 35 11]\n",
            " [36 37 38 39 40 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]\n",
            " [12  2 13 55  1 56  4 14 13 14 15  4 12  0  0  0  0  0  0  0]\n",
            " [ 3 57 58 59 60 61  5 62 63 15 64  1 65 66  3 67 68 69 70 71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUWlD3jiX10c",
        "colab_type": "code",
        "outputId": "99037ccb-8d5a-4880-ec8b-6440ca89d797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 97ms/step - loss: 1.1102 - acc: 0.3333\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 1.0996 - acc: 0.3333\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 333us/step - loss: 1.0891 - acc: 0.3333\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 237us/step - loss: 1.0786 - acc: 0.5000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 655us/step - loss: 1.0682 - acc: 0.6667\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 771us/step - loss: 1.0578 - acc: 0.8333\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 715us/step - loss: 1.0474 - acc: 0.8333\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 568us/step - loss: 1.0371 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 306us/step - loss: 1.0267 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 301us/step - loss: 1.0164 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9da851a400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "y1YbPNWIenE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demo using the model to make predictions."
      ]
    },
    {
      "metadata": {
        "id": "KcmpKvKUY_hK",
        "colab_type": "code",
        "outputId": "9ea53d36-66c3-46dc-cd5a-d6d7a4c1b1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9dsZSQnrqoU",
        "colab_type": "code",
        "outputId": "ecca890e-2c25-4c31-af0f-20597cb90342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.32128462 0.37047485 0.3082405 ]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0YtvaoazkuRT",
        "colab_type": "code",
        "outputId": "3c7dd606-f7e1-48eb-aa52-a10043f8e52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WDoo_fDVic2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
      ]
    },
    {
      "metadata": {
        "id": "1V1QLCxlikOI",
        "colab_type": "code",
        "outputId": "a35a1c98-a606-4ebe-d058-fe7249b71a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://Srinidhi-kv.github.io/deep_learning_hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mnN6zAHWqPnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
      ]
    },
    {
      "metadata": {
        "id": "in7or3F-jZju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Adding Three books from Gutenberg"
      ]
    },
    {
      "metadata": {
        "id": "srTpVrrS2irU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen \n",
        "\n",
        "url1 = \"http://www.gutenberg.org/files/120/120-0.txt\" #Treasure Island\n",
        "url2 = \"http://www.gutenberg.org/files/1184/1184-0.txt\" #Count of Mote Cristo\n",
        "url3 = \"http://www.gutenberg.org/cache/epub/1661/pg1661.txt\" #Sherlock Holmes\n",
        "\n",
        "raw1 = urlopen(url1).read().decode('utf-8')\n",
        "raw2 = urlopen(url2).read().decode('utf-8')\n",
        "raw3 = urlopen(url3).read().decode('utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgGgJ9-I2inI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_books(book_url, lines, label):\n",
        "  \n",
        "  book = urlopen(book_url).read().decode('utf-8')\n",
        "  book_clean= book.replace('\\r\\n', '')\n",
        "  \n",
        "  \n",
        "  x_split = book_clean.split('.')[1000:2000+lines]\n",
        "  x_train=[]\n",
        "  \n",
        "  i=0\n",
        "  for line in x_split:\n",
        "    if i>=lines:\n",
        "      break\n",
        "    if len(line)>10:\n",
        "      x_train.append(line)\n",
        "      i+=1\n",
        "  \n",
        "  y_train = list(np.full(lines, label))\n",
        "  \n",
        "  return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcCSDpHy8sHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train1, y_train1= clean_books(url1, 2500, 0)\n",
        "x_train2, y_train2= clean_books(url2, 2500, 1)\n",
        "x_train3, y_train3= clean_books(url3, 2500, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfypj2sC9INY",
        "colab_type": "code",
        "outputId": "46d67ad6-ab04-44af-fe12-1874cf029847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "x6qE1tBB9JO8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train1.extend(x_train2)\n",
        "x_train1.extend(x_train3)\n",
        "y_train1.extend(y_train2)\n",
        "y_train1.extend(y_train3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rr9H_29r98Kd",
        "colab_type": "code",
        "outputId": "ebbe63b4-676e-419e-a2af-1bc1d734345e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(y_train1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "JRiBKAo799hU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train1, y_train1, test_size=0.15, random_state=4356)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcAW25ZG_PnF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 2000\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvV6vFRR_6AY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "# print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QtWSagGVFmaW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = t.texts_to_sequences(x_test)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eS2mmDC1jieQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Vanilla Model"
      ]
    },
    {
      "metadata": {
        "id": "LZ-S5dYajljP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HB5fYzrsmCJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgAZKGpLjlnF",
        "colab_type": "code",
        "outputId": "876204ae-b15c-4b5d-d2c9-2d88d46398a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 16\n",
        "n_classes = 3\n",
        "epochs = 30\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile(optimizer, 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, 20, 16)            32000     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 963       \n",
            "=================================================================\n",
            "Total params: 32,963\n",
            "Trainable params: 32,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gQw_sXeyqU3k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8b_MGQmujtVW",
        "colab_type": "code",
        "outputId": "aef98a0a-fc8f-49db-98e7-6e6d43ed35db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, np.array(y_train), epochs= 50, validation_split=0.15, callbacks=[callback])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5418 samples, validate on 957 samples\n",
            "Epoch 1/50\n",
            "5418/5418 [==============================] - 4s 780us/step - loss: 1.0854 - acc: 0.4105 - val_loss: 1.0585 - val_acc: 0.5329\n",
            "Epoch 2/50\n",
            "5418/5418 [==============================] - 1s 164us/step - loss: 0.9624 - acc: 0.6764 - val_loss: 0.8900 - val_acc: 0.6782\n",
            "Epoch 3/50\n",
            "5418/5418 [==============================] - 1s 156us/step - loss: 0.7280 - acc: 0.7794 - val_loss: 0.7069 - val_acc: 0.7262\n",
            "Epoch 4/50\n",
            "5418/5418 [==============================] - 1s 161us/step - loss: 0.5409 - acc: 0.8422 - val_loss: 0.6020 - val_acc: 0.7638\n",
            "Epoch 5/50\n",
            "5418/5418 [==============================] - 1s 157us/step - loss: 0.4217 - acc: 0.8839 - val_loss: 0.5470 - val_acc: 0.7827\n",
            "Epoch 6/50\n",
            "5418/5418 [==============================] - 1s 161us/step - loss: 0.3405 - acc: 0.9085 - val_loss: 0.5225 - val_acc: 0.7921\n",
            "Epoch 7/50\n",
            "5418/5418 [==============================] - 1s 164us/step - loss: 0.2825 - acc: 0.9265 - val_loss: 0.5033 - val_acc: 0.8036\n",
            "Epoch 8/50\n",
            "5418/5418 [==============================] - 1s 162us/step - loss: 0.2362 - acc: 0.9428 - val_loss: 0.5020 - val_acc: 0.8056\n",
            "Epoch 9/50\n",
            "5418/5418 [==============================] - 1s 159us/step - loss: 0.2009 - acc: 0.9522 - val_loss: 0.5004 - val_acc: 0.8025\n",
            "Epoch 10/50\n",
            "5418/5418 [==============================] - 1s 163us/step - loss: 0.1709 - acc: 0.9633 - val_loss: 0.5053 - val_acc: 0.7962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f626a8e5e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "metadata": {
        "id": "TD3hLO-yj4-K",
        "colab_type": "code",
        "outputId": "86105f78-e235-47e2-e703-7a2087a69e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, np.array(y_test))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 0s 77us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4806314495404561, 0.7866666667196486]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "metadata": {
        "id": "3TmxpDrTg83b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('books_classification_embedding.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPlkBNjCkKyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Vanilla Model Test Accuracy: 79%"
      ]
    },
    {
      "metadata": {
        "id": "tQcOn9Kujlva",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "metadata": {
        "id": "uCWHEdnHBkv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(lr= 2*1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9SRPyrZt_8Ji",
        "colab_type": "code",
        "outputId": "2076179d-e82d-44fd-8667-f639cd67bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 128\n",
        "n_classes = 3\n",
        "epochs = 30\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(LSTM(64, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='relu', return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, kernel_initializer='glorot_normal', recurrent_initializer='glorot_normal', activation='sigmoid'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(GRU(64))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer, 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, 20, 128)           256000    \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 305,603\n",
            "Trainable params: 305,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ddHoJHmmlUwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQJSVME9A1aY",
        "colab_type": "code",
        "outputId": "f9af0f4d-057f-4cb8-d3b1-bc6f17bf0ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, np.array(y_train), epochs= 50, validation_split=0.15, callbacks= [callback], batch_size=32)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5418 samples, validate on 957 samples\n",
            "Epoch 1/50\n",
            "5418/5418 [==============================] - 15s 3ms/step - loss: 1.1113 - acc: 0.3472 - val_loss: 1.0964 - val_acc: 0.3720\n",
            "Epoch 2/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0954 - acc: 0.3562 - val_loss: 1.0956 - val_acc: 0.3281\n",
            "Epoch 3/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0912 - acc: 0.3680 - val_loss: 1.0894 - val_acc: 0.3511\n",
            "Epoch 4/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0848 - acc: 0.3852 - val_loss: 1.0880 - val_acc: 0.3605\n",
            "Epoch 5/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0762 - acc: 0.3970 - val_loss: 1.0798 - val_acc: 0.3866\n",
            "Epoch 6/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0631 - acc: 0.4219 - val_loss: 1.0686 - val_acc: 0.4148\n",
            "Epoch 7/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 1.0398 - acc: 0.4683 - val_loss: 1.0478 - val_acc: 0.4368\n",
            "Epoch 8/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.9943 - acc: 0.5386 - val_loss: 0.9971 - val_acc: 0.5392\n",
            "Epoch 9/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.8957 - acc: 0.6310 - val_loss: 0.8765 - val_acc: 0.6050\n",
            "Epoch 10/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.7416 - acc: 0.7060 - val_loss: 0.7458 - val_acc: 0.6938\n",
            "Epoch 11/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.6065 - acc: 0.7804 - val_loss: 0.6480 - val_acc: 0.7503\n",
            "Epoch 12/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.4984 - acc: 0.8331 - val_loss: 0.5743 - val_acc: 0.7774\n",
            "Epoch 13/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.4163 - acc: 0.8606 - val_loss: 0.5304 - val_acc: 0.7879\n",
            "Epoch 14/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.3597 - acc: 0.8791 - val_loss: 0.5074 - val_acc: 0.8025\n",
            "Epoch 15/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.3192 - acc: 0.8924 - val_loss: 0.4971 - val_acc: 0.8056\n",
            "Epoch 16/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.2883 - acc: 0.9029 - val_loss: 0.4930 - val_acc: 0.8119\n",
            "Epoch 17/50\n",
            "5418/5418 [==============================] - 11s 2ms/step - loss: 0.2726 - acc: 0.9081 - val_loss: 0.5009 - val_acc: 0.8067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f626a4a8ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "metadata": {
        "id": "EAmBXWm5BAQf",
        "colab_type": "code",
        "outputId": "52798f1f-95ca-4185-d87c-f83874729554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, np.array(y_test))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1125/1125 [==============================] - 1s 769us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5054080916908053, 0.8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "zPvj5J-n4t7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('books_classification_lstm.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0DLMY74jm7AW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### LSTM test accuracy: 80%\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D3oqFlUcnD2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model on Browser"
      ]
    },
    {
      "metadata": {
        "id": "7i_gNGivFX-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"Srinidhi-kv\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as this)\n",
        "USER_EMAIL = \"sk4356@columbia.edu\" \n",
        "\n",
        "# the user token you've created (see the lecture 8 slides for instructions)\n",
        "TOKEN = \"e0c2a9d915b1e08557d28b88764f47fa44a84628\" \n",
        "\n",
        "# site name\n",
        "# for example, if my user_name is \"foo\", then this notebook will create\n",
        "# a site at https://foo.github.io/hw4/\n",
        "SITE_NAME = \"deep_learning_hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tgK1LwMhn123",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UadpKzc9n86J",
        "colab_type": "code",
        "outputId": "00fdd09b-0591-42cb-c6cc-7a039828b727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Srinidhi-kv.github.io'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 32 (delta 7), reused 28 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VqoYhCeNn83h",
        "colab_type": "code",
        "outputId": "740e590b-b987-40eb-dc76-e994cc4b4a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir(repo_path)\n",
        "!git pull"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MZq4vdV_n81P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QmCIzZ7GoDMt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yh158VRqoDRB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_example = ' One of my last thoughts was of the captain, who had so often strode along the beachwith his cocked hat, his sabre-cut cheek, and his old brass telescope'\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjgHimppoDhY",
        "colab_type": "code",
        "outputId": "113674d1-e079-4c70-8a88-f34a27b489de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "# print(preds)\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w3X_c4JuTLca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yyTEypbQo4fL",
        "colab_type": "code",
        "outputId": "d7863ddb-d06d-49d4-d138-fac27ad39cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifcats in directory: /content/Srinidhi-kv.github.io/deep_learning_hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-PN_BaDoirw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Treasure Island</option>\n",
        "      <option value=\"example2\">Count of Monte Carlo</option>\n",
        "      <option value=\"example3\">Sherlock Holmes</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLd0hKLFoi4_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      ' One of my lastthoughts was of the captain, who had so often strode along the beachwith his cocked hat, his sabre-cut cheek, and his old brass telescope',\n",
        "  'example2':\n",
        "      ' Here is thepaper; do you know the writing?” As he spoke, Villefort drew the letterfrom his pocket, and presented it to Dantès',\n",
        "  'example3':\n",
        "      'But how could you guess what the motive was?'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xVr0_CCsoi9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-WRFB3HooioT",
        "colab_type": "code",
        "outputId": "1005d35d-775f-43e9-e5e4-e448e06dee3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master b1dfbfe] colab -> github\n",
            " 3 files changed, 2 insertions(+), 2 deletions(-)\n",
            " rewrite deep_learning_hw4/model_js/group1-shard1of1 (84%)\n",
            " rewrite deep_learning_hw4/model_js/model.json (92%)\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 1.08 MiB | 1.47 MiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/Srinidhi-kv/Srinidhi-kv.github.io/\n",
            "   8a88de5..b1dfbfe  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wPFNSvEdpYWT",
        "colab_type": "code",
        "outputId": "a8e07fcc-d416-4115-9e16-6cb18c83ef7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://Srinidhi-kv.github.io/deep_learning_hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "65EYRAAliBY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}